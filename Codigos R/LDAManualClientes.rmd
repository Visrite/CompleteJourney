---
title: "LDAManualClientes"
author: "Vicho"
date: "15-06-2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(arules)
library(tm)
library(slam)
library(car)
library(dplyr)
```

```{r}
options(scipen=999)
```


```{r}
load("LDAManualCorridoClientes.RData.RData")
```


```{r}
###### PARA LEER LA TABLA CON LDA
tr <- read.transactions('Canastasxcliente.csv', format = 'basket', sep=',', header = TRUE)
tr
summary(tr)

```



#Muestra
```{r}
#muestra de 1000 transacciones, de un total de 89949
set.seed(1)
tr_sample <- tr[sample(length(tr), 355)]

#muestra como lista (para lda)
tr_list <- as(tr_sample, "list")

#para lda
docs <- tr_list #en lda la lista de transacciones corresponderÃÂ­a a los documentos
#docs <- docs
#print(docs)
#save(docs,file="docs_10.Rdata")
```


```{r}
t <- as(tr, "matrix")
```


```{r}
#Poner los datos en matrix

t <- as(tr, "matrix") #Commodity en las columnas con su respectiva fila "True, False"
t <- 1*t #si es "True" = 1, otro caso 0
dim(t)
```


```{r}
set.seed(1)
t_sample <- t[sample(nrow(t), 355),]

dtm <- as.DocumentTermMatrix(t_sample, weighting = weightTf)

ind <- row_sums(dtm) == 0 #quitar documentos sin items, son 212
dtm <- dtm[!ind,]

```



```{r}
freq <- col_sums(dtm) #se suman las columnas

freq <- freq[order(freq, decreasing = TRUE)] #se ordenan de mayor a menor (los productos populares quedan primero)

term_count_table <-
  data.frame(
    Commodity_desc = names(freq),
    Count = unname(freq)
  )

#kable(term_count_table[1:25,]) #Conteo de commodity_desc 

```


#LDA Manual

```{r}
K <- 14 # number of topics
alpha <- 0.1 # hyperparameter. single value indicates symmetric dirichlet prior. higher=>scatters document clusters
eta <- .001 # hyperparameter
iterations <- 2000 # Poner más iteraciones # iterations for collapsed gibbs sampling.  This should be a lot higher than 3 in practice.

```

```{r}
## Assign WordIDs to each unique word
vocab <- unique(unlist(docs))

## Replace words in documents with wordIDs
for(i in 1:length(docs)) docs[[i]] <- match(docs[[i]], vocab)
```

```{r}
theta <- array(0, dim=c(length(docs),K,iterations))
phi <- array(0, dim=c(K,length(vocab),iterations))
```


```{r}
## 1. Randomly assign topics to words in each doc.  2. Generate word-topic count matrix.
wt <- matrix(0, K, length(vocab)) # initialize word-topic count matrix
ta <- sapply(docs, function(x) rep(0, length(x))) # initialize topic assignment list
for(d in 1:length(docs)){ # for each document
  for(w in 1:length(docs[[d]])){ # for each token in document d
    ta[[d]][w] <- sample(1:K, 1) # randomly assign topic to token w.
    ti <- ta[[d]][w] # topic index
    wi <- docs[[d]][w] # wordID for token w
    wt[ti,wi] <- wt[ti,wi]+1 # update word-topic count matrix     
  }
}
```

```{r}
dt <- matrix(0, length(docs), K)
for(d in 1:length(docs)){ # for each document d
  for(t in 1:K){ # for each topic t
    dt[d,t] <- sum(ta[[d]]==t) # count tokens in document d assigned to topic t   
  }
}
```




```{r}
t <- proc.time()
for(i in 1:iterations){ # for each pass through the corpus
  for(d in 1:length(docs)){ # for each document
    for(w in 1:length(docs[[d]])){ # for each token 
      
      t0 <- ta[[d]][w] # initial topic assignment to token w
      wid <- docs[[d]][w] # wordID of token w
      
      dt[d,t0] <- dt[d,t0]-1 # we don't want to include token w in our document-topic count matrix when sampling for token w
      wt[t0,wid] <- wt[t0,wid]-1 # we don't want to include token w in our word-topic count matrix when sampling for token w
      
      docs
      ## UPDATE TOPIC ASSIGNMENT FOR EACH WORD -- COLLAPSED GIBBS SAMPLING MAGIC.  Where the magic happens.
      denom_a <- sum(dt[d,]) + K * alpha # number of tokens in document + number topics * alpha
      denom_b <- rowSums(wt) + length(vocab) * eta # number of tokens in each topic + # of words in vocab * eta
      p_z <- (wt[,wid] + eta) / denom_b * (dt[d,] + alpha) / denom_a # calculating probability word belongs to each topic
      t1 <- sample(1:K, 1, prob=p_z/sum(p_z)) # draw topic for word n from multinomial using probabilities calculated above
      
      ta[[d]][w] <- t1 # update topic assignment list with newly sampled topic for token w.
      dt[d,t1] <- dt[d,t1]+1 # re-increment document-topic matrix with new topic assignment for token w.
      wt[t1,wid] <- wt[t1,wid]+1 #re-increment word-topic matrix with new topic assignment for token w.
      
      theta[,,i] <- (dt+alpha) / rowSums(dt+alpha) # topic probabilities per document
      phi[,,i] <- (wt + eta) / (rowSums(wt+eta)) # topic probabilities per word
      
    
      if(t0!=t1) print(paste0('doc:', d, ' token:' ,w, ' topic:',t0,'=>',t1)) # examine when topic assignments change
    }
  }
}
proc.time()-t
```


```{r}
alpha <- .1 # hyperparameter. single value indicates symmetric dirichlet prior. higher=>scatters document clusters
alpha2 <- rep(alpha,K)
loglike <- array(0,iterations)
for(i in 1:iterations){ # for each pass through the corpus
  loglike[i] <- 0
  for(d in 1:length(docs)){ # for each document
    for(w in 1:length(docs[[d]])){ # for each token 
      
    loglike[i] <- loglike[i]+log(phi[t1,wid,i]) #error de la suma, en la parte final hay que dejarla
      
    }
  }
}
```




```{r}
loglike2=data.frame(iter=seq(1,nrow(loglike)),loglike)
loglike2=loglike2[-1,]
ggplot(loglike2, aes(x=iter, y=loglike,)) + geom_line()
```


```{r}
a <- as.data.frame(theta)
a
```



```{r}
data <- c(1:355)
data <- as.data.frame(data)
data <- cbind(data, K1=c(0), K2=c(0),K3=c(0),K4=c(0),K5=c(0),K6=c(0),K7=c(0),K8=c(0),K9=c(0),K10=c(0),K11=c(0),K12=c(0),K13=c(0),K14=c(0))
```

```{r}
theta[1,2,]
```




```{r}
for(i in 1:355){
  for(d in 1:14){
     mean <- mean(theta[i,d,])
     data[i,d+1] <- mean
     
  }
}
```

```{r}
ThetaXcli <- cbind(t_sample,data[,2:15])
```



```{r}
save.image(file = "LDAManualCorridoCli.RData")
```








```{r}
for(i in 1:14){
  for(d in 1:400){
     plot(theta[d,i,],
          xlab = "Iteración",
          ylab = paste("theta[", i , ",", d,"]"))
  }
}
```


```{r}
for(i in 1:14){
  for(d in 1:243){
     plot(phi[i,d,],
          xlab = "Iteración",
          ylab = paste("phi[", i , ",", d,"]"))
  }
}
```


```{r}
for(i in 1:14){
  for(d in 1:400){

b <- theta[d,i,]
b <- as.data.frame(b)

a <- boxplot(b, plot = FALSE)

b<-b[!(b$b %in% a$out),]

plot(b,
     xlab = "Iteración",
     ylab = paste("theta[", i , ",", d,"]"))
  }
}
```


```{r}
for(i in 1:14){
  for(d in 1:243){

b <- phi[i,d,]
b <- as.data.frame(b)

a <- boxplot(b, plot = FALSE)

b<-b[!(b$b %in% a$out),]

plot(b,
     xlab = "Iteración",
     ylab = paste("phi[", i , ",", d,"]"))
  }
}
```



```{r}
theta2 <- (dt+alpha) / rowSums(dt+alpha) # topic probabilities per document
print(theta2)
```

```{r}
phi2 <- (wt + eta) / (rowSums(wt+eta)) # topic probabilities per word
colnames(phi2) <- vocab #hacer que aparezcan el nombre de la categoria
print(phi2)
```

```{r}
PBolManual <- colMeans(theta2)
PBolManual <- as.data.frame(PBolManual)
PBolManual <- t(PBolManual)
PBolManual <- as.data.frame(PBolManual)
```

```{r}
PBolManual <- rename(PBolManual, c("Conservas" = "V1", "Desayuno" = "V2" , "Bano" = "V3", "Comida Saludable" = "V4" , "Preparados" = "V5", "Cita" = "V6", "Despensa" = "V7", "Aperitivo" = "V8", "Fast Food" = "V9", "Cocina" = "V10", "Carrete" = "V11", "Colación" = "V12", "Compras rapidas" = "V13", "Hogar" = "V14"))
```

```{r}
PBolManual <- as.data.frame(t(PBolManual))
```



```{r}
phi1 <- as.data.frame(phi2)
phi2 <- as.data.frame(phi2)
```

```{r}
x <-c(names(phi1))
```

```{r}
phi1 <- rbind(phi1,x)
```


```{r}
phi1 <- t(phi1)
phi1 <- as.data.frame(phi1)
```






```{r}
phi1$V1 <- as.numeric(phi1$V1)
phi1$V2 <- as.numeric(phi1$V2)
phi1$V3 <- as.numeric(phi1$V3)
phi1$V4 <- as.numeric(phi1$V4)
phi1$V5 <- as.numeric(phi1$V5)
phi1$V6 <- as.numeric(phi1$V6)
phi1$V7 <- as.numeric(phi1$V7)
phi1$V8 <- as.numeric(phi1$V8)
phi1$V9 <- as.numeric(phi1$V9)
phi1$V10 <- as.numeric(phi1$V10)
phi1$V11 <- as.numeric(phi1$V11)
phi1$V12 <- as.numeric(phi1$V12)
phi1$V13 <- as.numeric(phi1$V13)
phi1$V14 <- as.numeric(phi1$V14)
```






```{r}

GA <- c()
GB <- c()
GC <- c()
GD <- c()
GE <- c()
GF <- c()
GG <- c()
GH <- c()
GI <- c()
GJ <- c()
GK <- c()
GL <- c()
GM <- c()
GN <- c()


for(i in 1:nrow(phi1)){ # for each pass through the corpus
  if(max(phi1[i,1:14]) == phi1[i,1]){
    GA <- c(GA, phi1[i,15]) #nombre
  }
  else if(max(phi1[i,1:14]) == phi1[i,2]){
    GB <- c(GB, phi1[i,15])
  }
    else if(max(phi1[i,1:14]) == phi1[i,3]){
    GC <- c(GC, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,4]){
    GD <- c(GD, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,5]){
    GE <- c(GE, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,6]){
    GF <- c(GF, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,7]){
    GG <- c(GG, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,8]){
    GH <- c(GH, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,9]){
    GI <- c(GI, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,10]){
    GJ <- c(GJ, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,11]){
    GK <- c(GK, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,12]){
    GL <- c(GL, phi1[i,15])
    }
    else if(max(phi1[i,1:14]) == phi1[i,13]){
    GM <- c(GM, phi1[i,15])
    }
    else{
    GN <- c(GN, phi1[i,15])
    }
}
```


```{r}
GA #Conservas / Enlatados /Despensa(?)
```

```{r}
GB #Desayuno
```

```{r}
GC #Baño
```

```{r}
GD #Comida Saludable
```

```{r}
GE #Preparados / Soltero(a)
```

```{r}
GF #Cita  / Soltero(a)2 
```

```{r}
GG #Despensa / Mercaderia
```

```{r}
GH #Aperitivo(?)/Comida general
```

```{r}
GI#Fast Food (Comida rápida)
```

```{r}
GJ #Cocina
```

```{r}
GK #Carrete / 
```

```{r}
GL #Lonchera /  Colación(?)
```

```{r}
GM #Compras rápidas / ("de pasada")
```

```{r}
GN #Hogar / Familia
```

```{r}
#Coorer k=14 con nombre y el phi
```

```{r}
phi1 <- rename(phi1, c("Conservas" = "V1", "Desayuno" = "V2" , "Bano" = "V3", "Comida Saludable" = "V4" , "Preparados" = "V5", "Cita" = "V6", "Despensa" = "V7", "Aperitivo" = "V8", "Fast Food" = "V9", "Cocina" = "V10", "Carrete" = "V11", "Colación" = "V12", "Compras rapidas" = "V13", "Hogar" = "V14"))
```

```{r}
phi1
```



#Save


```{r}
save.image(file = "LDAManualCorridoClientes.RData")
```





